{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тема “Обучение с учителем”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и Y из этих данных.\n",
    "Разбейте эти датафреймы н а тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "Y = pd.DataFrame(boston['target'], columns=['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484943"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values[:, 0])\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_model = r2_score(y_test, y_pred)\n",
    "R2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R2 из первого задания 0.71122, а R2 из второго задания 0.87472. Лучше работает модель RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestRegressor\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important = model.feature_importances_\n",
    "important.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdw0lEQVR4nO3dfbwdVX3v8c/XQHwIIFcT0SZgIkTTiMCNx+AVikYFE7QNKEoilYIPadRoRaGm9aViuVpo6+M1GiOmFXsxeqvxRoiEFp/wIpoDBDBINMQoh6g5gC80CkLgd/9YayeTfdbee044k8fv+/U6rzOzZq211549e/9m1sysUURgZmbW7jG7uwFmZrZncoAwM7MiBwgzMytygDAzsyIHCDMzKzpgdzdgJI0dOzYmTpy4u5thZrbXuOGGG+6OiHGlZftUgJg4cSL9/f27uxlmZnsNST/vtMxdTGZmVuQAYWZmRQ4QZmZW5ABhZmZFDhBmZlbkAGFmZkUOEGZmVuQAYWZmRQ4QZmZWtE/dSW1mtreYuPDKEatr48UvH7G6qnwEYWZmRQ4QZmZW5ABhZmZFjQYISTMlrZO0XtLCLvmeJ+lhSWcMt6yZmTWjsQAhaRSwCJgFTAXmSpraId8lwKrhljUzs+Y0eRXTdGB9RGwAkLQMmA3c1pbvbcBXgOftRFmznvaGq0XM9kRNdjGNB+6szA/ktG0kjQdOBxYPt6yZmTWryQChQlq0zX8MeHdEPLwTZVNGaZ6kfkn9g4ODO9FMMzMrabKLaQA4vDI/AdjUlqcPWCYJYCxwqqStNcsCEBFLgCUAfX19xSBiZmbD12SAWA1MljQJuAuYA7y2miEiJrWmJf0bcEVEfE3SAb3KmplZsxoLEBGxVdIC0tVJo4ClEbFW0vy8vP28Q8+yTbXVzMyGanQspohYCaxsSysGhog4p1dZMzPbdXwntZmZFTlAmJlZkQOEmZkVOUCYmVmRA4SZmRU5QJiZWZEDhJmZFTlAmJlZkQOEmZkVOUCYmVmRA4SZmRU5QJiZWZEDhJmZFTlAmJlZkQOEmZkVOUCYmVlRowFC0kxJ6yStl7SwsHy2pFskrZHUL+nEyrKNkm5tLWuynWZmNlRjT5STNApYBJwMDACrJa2IiNsq2a4BVkRESDoG+DIwpbJ8RkTc3VQbzcyssyaPIKYD6yNiQ0Q8CCwDZlczRMSWiIg8OwYIzMxsj9BkgBgP3FmZH8hpO5B0uqTbgSuB11cWBXC1pBskzWuwnWZmVtBkgFAhbcgRQkQsj4gpwGnARZVFJ0TENGAW8FZJJxVfRJqXz1/0Dw4OjkS7zcyMZgPEAHB4ZX4CsKlT5oj4LnCkpLF5flP+vxlYTuqyKpVbEhF9EdE3bty4kWq7mdl+r8kAsRqYLGmSpNHAHGBFNYOkoyQpT08DRgP3SBoj6eCcPgY4BfhRg201M7M2jV3FFBFbJS0AVgGjgKURsVbS/Lx8MfAq4GxJDwH3A2fmK5oOA5bn2HEAcHlEXNVUW83MbKjGAgRARKwEVralLa5MXwJcUii3ATi2ybaZmVl3vpPazMyKHCDMzKzIAcLMzIocIMzMrMgBwszMihwgzMysyAHCzMyKHCDMzKzIAcLMzIocIMzMrMgBwszMihwgzMysyAHCzMyKHCDMzKzIAcLMzIocIMzMrKjRACFppqR1ktZLWlhYPlvSLZLWSOqXdGLdsmZm1qzGAoSkUcAiYBYwFZgraWpbtmuAYyPiOOD1wKXDKGtmZg1q8ghiOrA+IjZExIPAMmB2NUNEbImIyLNjgKhb1szMmtVkgBgP3FmZH8hpO5B0uqTbgStJRxG1y+by83L3VP/g4OCINNzMzJoNECqkxZCEiOURMQU4DbhoOGVz+SUR0RcRfePGjdvpxpqZ2Y6aDBADwOGV+QnApk6ZI+K7wJGSxg63rJmZjbwmA8RqYLKkSZJGA3OAFdUMko6SpDw9DRgN3FOnrJmZNeuApiqOiK2SFgCrgFHA0ohYK2l+Xr4YeBVwtqSHgPuBM/NJ62LZptpqZmZDNRYgACJiJbCyLW1xZfoS4JK6Zc3MbNfxndRmZlbkAGFmZkUOEGZmVuQAYWZmRQ4QZmZW5ABhZmZFDhBmZlbkAGFmZkUOEGZmVuQAYWZmRQ4QZmZW5ABhZmZFDhBmZlbkAGFmZkUOEGZmVuQAYWZmRbUChKSXts2Pk7SsRrmZktZJWi9pYWH5WZJuyX/XSTq2smyjpFslrZHUX6edZmY2cuoeQVwoaS6ApHOB7wBf61ZA0ihgETALmArMlTS1LdvPgBdGxDHARcCStuUzIuK4iOir2U4zMxshdR85OhP4sqQLgJuBEyPi3h5lpgPrI2IDQD7imA3c1soQEddV8l8PTKjbcDMza1bdI4jRwOuBu4B7gZD0pB5lxgN3VuYHclonbwC+UZkP4GpJN0ia16mQpHmS+iX1Dw4O9miSmZnVVfcI4gbSD7aAo4FX5vlndCmjQloUM0ozSAHixEryCRGxSdJTgP+UdHtEfHdIhRFLyF1TfX19xfrNzGz4agWIiJi0E3UPAIdX5icAm9ozSToGuBSYFRH3VF5zU/6/WdJyUpfVkABhZmbNqHsEgaSjSSebH9dKi4jLuhRZDUyWNInUNTUHeG1bnUcAXwVeFxE/qaSPAR4TEb/L06cA/1C3rWZm9ujVChCS3g+8iBQgVpKuTPoe0DFARMRWSQuAVcAoYGlErJU0Py9fDLwPeDLwKUkAW/MVS4cBy3PaAcDlEXHVzrxBMzPbOXWPIM4AjgVuiohzJR1G6hbqKiJWkgJKNW1xZfqNwBsL5Tbk1zMzs92k7lVM90fEI8BWSYcAm+l+gtrMzPZydY8g+iUdCnyWdEXTFuCHjbXKzMx2u7pXMb0lTy6WdBVwSETc0lyzzMxsd6t7kvqkUlrpvgQzM9s31O1iuiD/PxG4lnQTXOD7EszM9ll1u5j+HEDSTRHxF802yczM9gTDfR6Eh7IwM9tP1D0H8c48+ZTKNBHxkUZaZWZmu13dcxAH5/+frUybmdk+rO45iA9U5yUdEBFbm2mSmZntCeo+cvTNku6S9AZJPwQGJb2p4baZmdluVLeLaQFpsL41wLOBh4D/InU5mZnZPqhugHggIn4qaV1EbASQ9EBzzTIzs92t7mWuPwOIiGkAkg4CHmmqUWZmtvvVChARcUbb/BbgBY20yMzM9gh174N4ZYdFXx3BtpiZ2R6kbhfTl4ALgVcAf57/XtGrkKSZktZJWi9pYWH5WZJuyX/XSTq2blkzM2tW3ZPURwMXAQcB742Idb0KSBoFLAJOBgaA1ZJWRMRtlWw/A14YEb+RNAtYAhxfs6yZmTWo7jmIdRHxGuBi4COSPitpfI9i04H1EbEhIh4ElgGz2+q9LiJ+k2evBybULWtmZs2qew7if7F9oL4NwAuBnwJP6FJsPHBnZX4AOL5L/jcA3xhuWUnzgHkARxxxRJfqzcxsOGo/crTHfIkKacXRYCXNIAWIE4dbNiKWkLqm6Ovr82izZmYjpO5YTJ+XNBqYQvqhXpe7froZAA6vzE8ANrVnknQMcCkwKyLuGU5ZMzNrTt2xmE4F7gA+AXwSWJ9PKnezGpgsaVIOLnOAFW31HkG6VPZ1EfGT4ZQ1M7Nm1e1i+ggwIyLWA0g6EriS7ecMhoiIrZIWAKuAUcDSiFgraX5evhh4H/Bk4FOSALZGRF+nsjv1Ds3MbKfUDRCbW8Eh2wBs7lUoIlYCK9vSFlem3wi8sW5ZMzPbdeoGiLWSVgJfJp2DeDXp3oRXAkSE76g2M9vH1A0QjwN+Tbq8FWAQeBLpjurAQ26Yme1z6l7FdG7TDTEzsz1L1wAh6RPdlkfE20e2OWZmtqfodQQxm3SlkZmZ7Wd6BYh7I+Lzu6QlZma2R+l1o5yHrjAz20/VfR6EmZntZ3p1MR0r6beFdAEREYc00CYzM9sDdA0QETFqVzXEzMz2LO5iMjOzIgcIMzMrcoAwM7MiBwgzMytygDAzsyIHCDMzK2o0QEiaKWmdpPWSFhaWT5H0fUl/lHR+27KNkm6VtEZSf5PtNDOzoeo+D2LYJI0CFgEnAwOkBwytiIjbKtnuBd4OnNahmhkRcXdTbTQzs86aPIKYDqyPiA0R8SCwjDQ67DYRsTkiVgMPNdgOMzPbCU0GiPHAnZX5gZxWVwBXS7pB0rxOmSTNk9QvqX9wcHAnm2pmZu2aDBAqpA1ndNgTImIaMAt4q6STSpkiYklE9EVE37hx43amnWZmVtBkgBgADq/MTwA21S0cEZvy/83AclKXlZmZ7SJNBojVwGRJkySNBuYAK+oUlDRG0sGtaeAU4EeNtdTMzIZo7CqmiNgqaQGwChgFLI2ItZLm5+WLJT0V6AcOAR6R9A5gKjAWWC6p1cbLI+KqptpqZmZDNRYgACJiJbCyLW1xZfpXpK6ndr8Fjm2ybWZm1p3vpDYzsyIHCDMzK3KAMDOzIgcIMzMrcoAwM7MiBwgzMytygDAzsyIHCDMzK3KAMDOzIgcIMzMrcoAwM7MiBwgzMytygDAzsyIHCDMzK3KAMDOzIgcIMzMrajRASJopaZ2k9ZIWFpZPkfR9SX+UdP5wypqZWbMaCxCSRgGLgFmkx4jOlTS1Ldu9wNuBf9mJsmZm1qAmjyCmA+sjYkNEPAgsA2ZXM0TE5ohYDTw03LJmZtasJgPEeODOyvxAThvRspLmSeqX1D84OLhTDTUzs6GaDBAqpMVIl42IJRHRFxF948aNq904MzPrrskAMQAcXpmfAGzaBWXNzGwENBkgVgOTJU2SNBqYA6zYBWXNzGwEHNBUxRGxVdICYBUwClgaEWslzc/LF0t6KtAPHAI8IukdwNSI+G2pbFNtNTOzoRoLEAARsRJY2Za2uDL9K1L3Ua2yZma26/hOajMzK3KAMDOzIgcIMzMrcoAwM7MiBwgzMytygDAzsyIHCDMzK3KAMDOzIgcIMzMrcoAwM7MiBwgzMytygDAzs6JGB+szs0dn4sIrR6yujRe/fMTqsv2DjyDMzKzIAcLMzIocIMzMrKjRACFppqR1ktZLWlhYLkmfyMtvkTStsmyjpFslrZHU32Q7zcxsqMZOUksaBSwCTgYGgNWSVkTEbZVss4DJ+e944NP5f8uMiLi7qTaamVlnTR5BTAfWR8SGiHgQWAbMbsszG7gskuuBQyU9rcE2mZlZTU0GiPHAnZX5gZxWN08AV0u6QdK8Ti8iaZ6kfkn9g4ODI9BsMzODZgOECmkxjDwnRMQ0UjfUWyWdVHqRiFgSEX0R0Tdu3Lidb62Zme2gyQAxABxemZ8AbKqbJyJa/zcDy0ldVmZmtos0GSBWA5MlTZI0GpgDrGjLswI4O1/N9Hzgvoj4paQxkg4GkDQGOAX4UYNtNTOzNo1dxRQRWyUtAFYBo4ClEbFW0vy8fDGwEjgVWA/8ATg3Fz8MWC6p1cbLI+KqptpqZmZDNToWU0SsJAWBatriynQAby2U2wAc22TbzMysO99JbWZmRQ4QZmZW5ABhZmZFfh5E5nH3zcx25CMIMzMrcoAwM7MiBwgzMytygDAzsyIHCDMzK3KAMDOzIl/mamZ7LV+e3iwfQZiZWZGPIGy325v3Avfmtpv14gBhZo3ZmwPo3tz2keIuJjMzK/IRxD7Aezpm1oRGA4SkmcDHSU+UuzQiLm5brrz8VNIT5c6JiBvrlDWzR887F9ZNY11MkkYBi4BZwFRgrqSpbdlmAZPz3zzg08Moa2ZmDWryCGI6sD4/PhRJy4DZwG2VPLOBy/KjR6+XdKikpwETa5Tdq+zNe2p7c9vNbOcp/TY3ULF0BjAzIt6Y518HHB8RCyp5rgAujojv5flrgHeTAkTXspU65pGOPgCeBaxr5A0lY4G7Xf9uqX9vbrvr3311u/7enh4R40oLmjyCUCGtPRp1ylOnbEqMWAIsGV7Tdo6k/ojoc/27vv69ue2uf/fV7fofnSYDxABweGV+ArCpZp7RNcqamVmDmrwPYjUwWdIkSaOBOcCKtjwrgLOVPB+4LyJ+WbOsmZk1qLEjiIjYKmkBsIp0qerSiFgraX5evhhYSbrEdT3pMtdzu5Vtqq3D0HRXluvfPXW7/t1b/97c9n2h/o4aO0ltZmZ7Nw+1YWZmRQ4QZmZWFhH79R/wVGAZcAfpRryVwDOB+4E1Oe0y4MCc/0XAFXn6HNLlty+p1Hd6Tjujw+udnuut/j0CvDmXe1sl7ydJw49Uy2/J/yd2yw/8G/Az4GbgJ/k9jG+vpzJ/DvDJPP0s4DrgN8CD+X9rvfyordyFwPmV+QNI12z/Y1u+VwA35fbcBvx1ZVkAH67Mnw9cWJmfB9ye/34InJjT3wl8rpLvLODKLp/1w3l9/wj4OnBo27q8qJJ3LPBQa53U2I5an/uUStp04NvAT4EbgSuB51TW211t28GhNdq+Nq/DdwKPKWyThwFXVNbzyh7tLq6TyvKbgS+2pXXdttryPrny/n7V9p4Py+u4ui0cnNfjbblN/wH8OL9OqY7Rw3kPpPOcrbIPArfm6YupfAe6bXdt6+3m/Nm+oMY2sqWQ9qy8jazJ73MJ8LJKG7eQ7u1aQ7qpeMi2BvwgL/8FMFgpO/FR/z4+2gr25j/S/RbfB+ZX0o4D/oz8Q0g6Sf5N4KzCl/Ec4BbSWFGt8l/KH04xQBTaMA/4DvAM4NekE/aj87JeAaJjftKX+IzK+zwvf8lGV+up1Lvty0G6OOD21noBntO+XirlLmTHAHEq8P9IAbd1jutA0mXKE/L8Y4FnVco8QPrBGZvntwUIUmC5obJsWv4iPJUUjNYAJwCH5jqe0WVdb6lMfx54T2Vd3gHcVFn+5lx33QDxZeDaSrsPAzZS+eEATgROK623GvVX2/4U4L+ADxS2yc8Af1PJe8ww6t22TvL8n5J+QO8CxlTSu25bXV6rfVt5S15n327L9wBwdZ5eA1zXqY6dfQ952cbWdlX4DnTc7gqv+TLgO8P5DCtpq4DZlfnntC3/NtDXbVsrtX+k/vb3LqYZwEORrqgCICLWAHdW5h8m7T2M71DHtcB0SQdKOgg4irRR9yTpmcD7gNeRjiIGgWuAv6rZ/lr5I/koae9rVo16jwL+0FovEXFr+3rpYi5pkMVfAM/PaQeTfszvyfX9MSKqd7xvJe05nVeo793ABRFxdy57I+lH4K0RsZX0I7MI+CfS1W4barQR0o5B9TO9H/ixpNYNSWeSvog95c/9BOANpEuyARYAn4+I61r5IuJ7EfG1mu3rKCI2k3YsFuQBL6ueRrq/qJX3lmFU3b5OXgt8Abga+IsObRnutlU1F3gXMEFS9XW3Ao9I+lvS/VA/Hkadw34PHXTc7gp5DyEdZe+M9s/r1m6ZO2xrjdnfA8TRpL2EjiQ9DjgeuKpDliDtzb2MNF5Urfs1JB0IXE7aG/pFZdHFwLvygIV1DCf/jcCUGvmuB54t6RuSzpN0aGXZkZLWtP6A+a0Fkh4PvITUxfFF0g8AEXEvab38XNIXJZ0lqX3bWwScJemJbenPZuhn1J/TyT/APwZeSgoSPeV19RKGflbLgDmSJpC6EOrenHkacFVE/AS4V9K03L4be5Q7r7Iuv1XztQDIgfAxpKOJqkXA5yR9S9J7JP1Jnfo6rJMzSUfE2z7LLupuW63XO5y0N/5DUiA+sy3LO4BLSDsl/TXrfLTvoarrdgc8Pn9utwOXAhcNo+6qjwLf7PBdKylta43Z3wNEN0fmH8B7gF/02BNbRormc0gbYh0XAWsjYlk1MSJ+RjpieW2dSoaZvzSEyQ7V5f8/IO0t/R9S98X1kh6bl90REce1/oDFlfKvAL4VEX8AvgKc3gpckcbVeklu6/nA0rb38VtSX/bba76P1L+R9qj6SN1YxfFkKh5f+UyfBPxn2/KrgJNJPyRfqtGOlrmkbYD8f8gPkaQfSPqxpI9Xkj9aWZczhvF626ptT4iIVaTuys+SfrBvktRtvRTXiaTnAYMR8XPSUeo0Sf9tOG3pYQ7bj9Da19nj82tuzfOf61HXSL2HXrZtd8D9+XObAswELisczfUUEf9K6gYrfddKem5rI2l/DxBrged2WHZH/gE8Cni+pI6Hp3kv6GhSf+VPer2opBcBryJ1Q5R8iHSIW/fzqZv/v7P9cP3+fJd6y5PYPiDYWtIJsKURMZv0RT26RjvmAi+VtJG09/VkUjcesK2r6qOkH+FXFcp/jHToPKaSdhtDP6NpbB/Z9wPAvwMfJO2NdXN//kyfTjq5uUN3QUQ8mNv9LlKA60nSk4EXA5fm930Baa91bW5nq+7jgfcC7UdIO0XSM0hHOZvbl0XEvRFxeUS8jjQqwUldquq0TuYCU/J7uoPUjVL6zFqq21Ydc4Fzcv0rgGMlTc7LHgD+CEwibQu9jkxG6j1U9drutomI75Muaui1g1IUEZvqfNc6bWs7E5jq2t8DxDeBx0p6Uysh73U8vTUfaeiPhcDf9ajr74C/7/WCeQ/mX4GzI+J3pTwRcTtpQ3xFr/rq5M9Dmbyd1N/Z6ir7DvCXefnjgdcArW6OA4HHSXqTpKeSfujHUVkvhdc4hHQS9oiImBgRE0lf1LmSDspBseU44OeF93Evaa/yDZXkfwIuyV8OJB1HOhn3KUnPAV5O6opYAjxd0smd2lh5nftIRyrn566+qg8D746Ie3rVk51Burrk6fl9H046WX416QfwBZW8T6hZZ1f5iGAx6YRktC17saQn5OmDgSNJ54O6alsnjwVeTTrB3fosZ1M+MiptW73a/yzSCePxlfr/ke196qOBD0XEAOlqrUV1fgR39j100HG7K7yfKaSLWepuM9WyM1vbYOW7dleH7J22tROH+7p17dePHI2IkHQ68DFJC0l7LhtJ/Z9VXwMulPRnXer6Rs2XnU/qN/502zbf3jX1QdJloXWV8v+zpPeSfpiuB2bkvWSAvwE+k7/cIm14383LTiEdUfwz6cqoQeBtDF0vVa8EvhkRf6yk/V/SF+2dwN9K+gzpZPDvSV+2kg9TObKKiBX5BOZ1kgL4HSmw/Yp0WH5eRDwAIOktpEP94yrvsygibpJ0M+lH6dpK+lrS3n9dc0nngaq+QuryO5P0IzOetKd/N/APlXznSfrLyvxpEbGxw+u0ulEOJO1lfgH4SCHfc4FPStpK2gG8NCJW13kjlXXyGuCuiKj+UH0XmKr0vBbovm31MhdY3pb2FWCZpOtzuz+X2/T1vAN3Nqnbc0TeQ97x61ZPcburlGt9HpC+P3+VL2jp5gmSBirzHyENRPpxSQ/ktAsi4lcdynfb1q4dmv3R81AbZmZWtL93MZmZWQcOEGZmVuQAYWZmRQ4QZmZW5ABhZmZFDhC2z5L0cB4O4WZJN7bdk2BmPfgyV9tnSdoSEQfl6ZcBfx8RL9zNzTLba/gIwvYXO4y4KekCSasl3SLpA5X0s3PazZK+0F6JpAsl3aXtg+zd17pLXNIWSR/ORyvXtMZAkvRt5VFiJf1PSVvy9DGS+iXdlNsyJadvlDQ2T4/NwyogaaKka3P9246IJL1I0hV5+oVK4z49Md/Bfk3Oe6uk2Q2sV9uH7dd3Uts+r3W36+NIQ0G8GEDSKcBk0gN9BKyQdBJpqIT3ACdExN2SntSh3o9GxL/kuq6opI8BboyId0l6H/B+KneFS3oKacBCYNtQ3K3A8SHSsO3dhnTZDJwcEQ8ojVv0xVb5XMdzSEOtnxoR90k6ADg9In6bA871kla0D89h1okDhO3LWoO4Iel/kIbhOJo0lMgpbB+a5CBSwDgW+I/KMwDuHebrPcL2UWD/Hfhq2/L3kgZW3DasiqRTSUN0P8yOz1P4lqSHSWP8tBxIGkbjuJz/mZVlfwJ8g/RkvtYw5QI+lIPfI6TnJBxGGqbErCd3Mdl+oW3ETZEeidoaavuoiPgcOw7nPCIvW5meCBwdEV9va9fKiJhEGnvotMqiGTm4VYcBP4/0FMFjSUcO1dF4p5AenvTX2j6891mk9/vcXNevSUdTZrU4QNh+oW3EzVXA65WeJYGk8bn75xrgNZURPDt1MXXyGNKIm5AGUPteZdn781+1TdWhvx+g95DqTwR+GRGPkJ5CWD26+GZErCAdoXy8kn9zRDwkaQZdRuM1K3EXk+3LOo24ebWkPwW+n0fU3UIaqXOtpA8C38ndOzfRedTZkt+TnsR3A3AfOz4lbaAyWm7LiyW1RnfdApzbo/5PAV+R9GrS0Oy/b88QEZcpPbHvVOB/A1+X1E96DO7tw3gvZr7M1WykVC+rNdsXuIvJzMyKfARhZmZFPoIwM7MiBwgzMytygDAzsyIHCDMzK3KAMDOzov8PRp9JIJJ6zGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(X_test.columns, important)\n",
    "\n",
    "plt.xlabel(\"Вес признака\")\n",
    "plt.ylabel(\"Признак\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Наибольшую важность показывают признаки RM и LSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими. Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументовмассивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(df['Class'])\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (199364, 30) X_test.shape: (85443, 30) y_train.shape: (199364,) y_test.shape: (85443,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape:', X_train.shape, 'X_test.shape:', X_test.shape, 'y_train.shape:', y_train.shape, 'y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=RandomForestClassifier(random_state=100), \n",
    "                  param_grid=parameters, \n",
    "                  scoring='roc_auc', \n",
    "                  cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
       "                          'max_features': array([3, 4]),\n",
       "                          'n_estimators': [10, 15]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, max_features=3, n_estimators=15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=6, max_features=3, n_estimators=15)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00055894, 0.00038644, 0.00031831, ..., 0.00035994, 0.0004508 ,\n",
       "       0.00079785])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = forest.predict_proba(X_test)\n",
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408486524510324"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
